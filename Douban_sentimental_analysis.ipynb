{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code for sentimental analysis(preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from opencc import OpenCC\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_char(string):\n",
    "    return re.sub('[a-zA-Z0-9]','',string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t2s(string):\n",
    "    opencc = OpenCC('t2s')\n",
    "    return opencc.convert(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word to id,id to word"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "movie_comments = pd.read_csv('./movie_comments.csv')\n",
    "\n",
    "movie_comments = movie_comments.dropna(subset=['comment','star'])\n",
    "\n",
    "movie_comments = movie_comments.drop(568,axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def cut(string): return ' '.join([w for w in jieba.cut(string)])\n",
    "\n",
    "movie_comments['word_sequence'] = movie_comments.comment.apply(remove_char)\n",
    "\n",
    "movie_comments['word_sequence'] = movie_comments.word_sequence.apply(t2s)\n",
    "\n",
    "movie_comments['word_sequence'] = movie_comments.word_sequence.apply(cut)\n",
    "\n",
    "movie_comments.to_pickle('./movie_comments_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./movie_comments_data.pkl','rb') as f:\n",
    "    movie_comments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = Counter()\n",
    "for s in movie_comments['word_sequence']:\n",
    "    for w in s.split():\n",
    "        word_count[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'å´äº¬': 279,\n",
       "         'æ„æ·«': 281,\n",
       "         'åˆ°': 10373,\n",
       "         'äº†': 102381,\n",
       "         'è„‘æ®‹': 319,\n",
       "         'çš„': 328466,\n",
       "         'åœ°æ­¥': 197,\n",
       "         'ï¼Œ': 353805,\n",
       "         'çœ‹': 34250,\n",
       "         'æ¶å¿ƒ': 943,\n",
       "         'æƒ³': 7474,\n",
       "         'å': 574,\n",
       "         'é¦–æ˜ ç¤¼': 42,\n",
       "         'ã€‚': 219514,\n",
       "         'å¤ª': 13043,\n",
       "         'ææ€–': 599,\n",
       "         'è¿™ä¸ª': 10282,\n",
       "         'ç”µå½±': 34614,\n",
       "         'ä¸è®²é“ç†': 8,\n",
       "         'å®Œå…¨': 4152,\n",
       "         'å°±æ˜¯': 14015,\n",
       "         'åœ¨': 31161,\n",
       "         'å®ç°': 270,\n",
       "         'ä»–': 10663,\n",
       "         'å°': 6649,\n",
       "         'ç²‰çº¢': 39,\n",
       "         'è‹±é›„': 1706,\n",
       "         'æ¢¦': 885,\n",
       "         'å„ç§': 3143,\n",
       "         'è£…å¤‡': 83,\n",
       "         'è½®ç•ª': 21,\n",
       "         'ä¸Šåœº': 17,\n",
       "         'è§†': 29,\n",
       "         'ç‰©ç†': 63,\n",
       "         'é€»è¾‘': 1417,\n",
       "         'äº': 1783,\n",
       "         'ä¸é¡¾': 57,\n",
       "         'ä¸å¾—ä¸': 670,\n",
       "         'è¯´': 11120,\n",
       "         'æœ‰é’±': 205,\n",
       "         'çœŸ': 5188,\n",
       "         'å¥½': 23131,\n",
       "         'éšæ„': 170,\n",
       "         'èƒ¡é—¹': 45,\n",
       "         'ç‚’ä½œ': 70,\n",
       "         'æ°´å¹³': 819,\n",
       "         'ä¸è¾“': 48,\n",
       "         'å†¯å°åˆš': 266,\n",
       "         'ä½†å°åˆš': 1,\n",
       "         'è‡³å°‘': 912,\n",
       "         'ä¸ä¼š': 2683,\n",
       "         'ç”¨': 3923,\n",
       "         'ä¸»æ—‹å¾‹': 928,\n",
       "         'æ¥': 5261,\n",
       "         'â€¦': 26199,\n",
       "         'è®©': 13702,\n",
       "         'äºº': 24152,\n",
       "         'ä¸': 28538,\n",
       "         'èˆ’æœ': 611,\n",
       "         'ä¸ºäº†': 3509,\n",
       "         'è€Œ': 6533,\n",
       "         'ç…½æƒ…': 1186,\n",
       "         'è§‰å¾—': 8879,\n",
       "         'æ˜¯': 72724,\n",
       "         'ä¸ª': 6557,\n",
       "         'å¤§': 5902,\n",
       "         'åšä½œ': 839,\n",
       "         'ã€': 18329,\n",
       "         'è°è¨€': 269,\n",
       "         'å®¶': 569,\n",
       "         'ï¼ˆ': 4911,\n",
       "         '.': 14403,\n",
       "         'æ›´æ–°': 87,\n",
       "         'ï¼‰': 4618,\n",
       "         'ç‰‡å­': 9594,\n",
       "         'æ•´ä½“': 1410,\n",
       "         'ä¸å¦‚': 1806,\n",
       "         'æ¹„å…¬æ²³': 57,\n",
       "         'è¡ŒåŠ¨': 187,\n",
       "         'ä¸å¤Ÿ': 1820,\n",
       "         'æµç•…': 702,\n",
       "         'ç¼–å‰§': 2274,\n",
       "         'æœ‰æ¯’': 38,\n",
       "         'å°è¯': 2370,\n",
       "         'å°´å°¬': 1677,\n",
       "         'ï¼›': 5322,\n",
       "         'åˆ»æ„': 1042,\n",
       "         'æ˜¾å¾—': 1098,\n",
       "         'å¦‚æ­¤': 2686,\n",
       "         'ä¸åˆæ—¶å®œ': 33,\n",
       "         'åˆ': 11553,\n",
       "         'å¤šä½™': 311,\n",
       "         'å‡­è‰¯å¿ƒè¯´': 3,\n",
       "         'çœ‹åˆ°': 5459,\n",
       "         'ä¸åƒ': 277,\n",
       "         'ã€Š': 12004,\n",
       "         'æˆ˜ç‹¼': 36,\n",
       "         'ã€‹': 12003,\n",
       "         'ç»­é›†': 710,\n",
       "         'å®Œè™': 7,\n",
       "         'ä¸­äºŒå¾—': 5,\n",
       "         'å¾ˆ': 34752,\n",
       "         'â€œ': 11369,\n",
       "         'çŠ¯': 181,\n",
       "         'æˆ‘': 50062,\n",
       "         'ä¸­å': 55,\n",
       "         'è€…': 548,\n",
       "         'è™½è¿œå¿…': 22,\n",
       "         'è¯›': 33,\n",
       "         'â€': 11160,\n",
       "         'æ¯”': 6098,\n",
       "         'è¿™å¥': 231,\n",
       "         'è¯': 1758,\n",
       "         'è¿˜è¦': 780,\n",
       "         'ä¸€ç™¾å€': 14,\n",
       "         'è„‘å­': 295,\n",
       "         'ä¸œè¥¿': 2291,\n",
       "         'å¸Œæœ›': 1962,\n",
       "         'ä»¬': 2487,\n",
       "         'éƒ½': 36327,\n",
       "         'èƒ½': 9626,\n",
       "         'æœ‰': 27739,\n",
       "         'ä¸‰æ˜Ÿ': 2055,\n",
       "         'åŠ': 2053,\n",
       "         'å®æ‰“å®': 26,\n",
       "         'åˆ†': 2812,\n",
       "         'ç¬¬ä¸€é›†': 211,\n",
       "         'çˆ±å›½': 136,\n",
       "         'å†…éƒ¨': 115,\n",
       "         'åš': 4429,\n",
       "         'ç€': 6992,\n",
       "         'ç½®æ¢': 18,\n",
       "         'ä¸': 9532,\n",
       "         'è¾ƒåŠ²': 17,\n",
       "         'ä½†': 15535,\n",
       "         'ç¬¬äºŒé›†': 69,\n",
       "         'æ‰': 4959,\n",
       "         'çœŸæ­£': 1484,\n",
       "         'æ˜¾éœ²': 17,\n",
       "         'é‡å¿ƒ': 262,\n",
       "         'ç»ˆäº': 1777,\n",
       "         'æŠ›å¼ƒ': 225,\n",
       "         'æå¿ å¿—': 2,\n",
       "         'æ–°å¢': 7,\n",
       "         'å¤–æ¥': 28,\n",
       "         'ç­åº•': 73,\n",
       "         'ç¡¬ä»¶': 24,\n",
       "         'å®åŠ›': 194,\n",
       "         'æœºä¼š': 386,\n",
       "         'å’Œ': 31337,\n",
       "         'å›½é™…': 208,\n",
       "         'æ¥è½¨': 7,\n",
       "         'å¼€ç¯‡': 193,\n",
       "         'æ°´ä¸‹': 33,\n",
       "         'é•¿é•œå¤´': 689,\n",
       "         'è¯¸å¦‚': 40,\n",
       "         'é“ä¸ç½‘': 3,\n",
       "         'æ‹¦æˆª': 9,\n",
       "         'å¼¹å¤´': 8,\n",
       "         'ç»†èŠ‚': 2268,\n",
       "         'è®¾è®¡': 1177,\n",
       "         'å›½äº§': 1119,\n",
       "         'åŠ¨ä½œç‰‡': 1111,\n",
       "         'é‡æ–°': 452,\n",
       "         'å°é¡¶': 4,\n",
       "         'ç†å¿µ': 113,\n",
       "         'ä¸Š': 10113,\n",
       "         'å®ƒ': 3303,\n",
       "         'ç”šè‡³': 1278,\n",
       "         'åšåˆ°': 533,\n",
       "         'ç»£æ˜¥åˆ€': 37,\n",
       "         'æœ€': 8612,\n",
       "         'æƒ³åšåˆ°': 5,\n",
       "         'é‚£': 7414,\n",
       "         'éƒ¨åˆ†': 1952,\n",
       "         'æƒŠé™©': 107,\n",
       "         'å¤§æ°”': 184,\n",
       "         'å¼•äººå…¥èƒœ': 103,\n",
       "         'ç»“åˆ': 423,\n",
       "         'ä¸ä¿—': 76,\n",
       "         'å¿«': 1200,\n",
       "         'å‰ªä¸‹': 2,\n",
       "         'çœŸåˆ€çœŸæª': 4,\n",
       "         'ä¸ç¦': 137,\n",
       "         'çƒ­è¡€æ²¸è…¾': 225,\n",
       "         'ç‰¹åˆ«': 2699,\n",
       "         'å¼¹ç°§åºŠ': 3,\n",
       "         'æ¶': 57,\n",
       "         'æŒ¡': 73,\n",
       "         'ç‚¸å¼¹': 100,\n",
       "         'ç©ºæ‰‹': 9,\n",
       "         'æ¥': 330,\n",
       "         'ç¢ç»ç’ƒ': 4,\n",
       "         'å¼¹åŒ£': 2,\n",
       "         'å‰²å–‰': 11,\n",
       "         'ç­‰': 1771,\n",
       "         'å¸…': 1045,\n",
       "         'å¾—': 10017,\n",
       "         'é£èµ·': 39,\n",
       "         'ï¼': 55075,\n",
       "         'å°±ç®—': 902,\n",
       "         'å‰åŠæ®µ': 588,\n",
       "         'é“ºå«': 587,\n",
       "         'èŠ‚å¥': 3517,\n",
       "         'æ•£æ¼«': 64,\n",
       "         'ä¸»è§’': 2141,\n",
       "         'å…‰ç¯': 217,\n",
       "         'å¼€å¤ªå¤§': 3,\n",
       "         'ä¹Ÿ': 32070,\n",
       "         'ä¸æ€•': 135,\n",
       "         'ä½œä¸º': 2412,\n",
       "         'ä¸€ä¸ª': 17829,\n",
       "         'ä¸­å›½': 3582,\n",
       "         'ä¸¤ä¸ª': 2953,\n",
       "         'å°æ—¶': 1807,\n",
       "         'å¼¥æ¼«ç€': 37,\n",
       "         'å¼ºå¤§': 694,\n",
       "         'ä¸å¯': 516,\n",
       "         'ä¾µçŠ¯': 24,\n",
       "         'æ°›å›´': 559,\n",
       "         'è¿˜æ˜¯': 16858,\n",
       "         'é‚£é¢—': 47,\n",
       "         'æ°‘æ—': 326,\n",
       "         'è‡ªè±ª': 24,\n",
       "         'å¿ƒ': 1091,\n",
       "         'ç °ç °': 53,\n",
       "         'ç °': 58,\n",
       "         'è·³ä¸ª': 1,\n",
       "         'ä¸åœ': 436,\n",
       "         '/': 6322,\n",
       "         'å†·å³°': 1,\n",
       "         'è¿™éƒ¨': 7641,\n",
       "         'é‡Œ': 7888,\n",
       "         'å³': 375,\n",
       "         'åƒ': 5727,\n",
       "         'æˆé¾™': 885,\n",
       "         'åƒæ°': 2,\n",
       "         'æ£®æ–¯å¦': 150,\n",
       "         'æ£®': 157,\n",
       "         'ä½“åˆ¶': 213,\n",
       "         'å¤–': 501,\n",
       "         'åŒ': 573,\n",
       "         'ç±»å‹': 1511,\n",
       "         'æ€»æ˜¯': 1988,\n",
       "         'ä»£è¡¨': 471,\n",
       "         'ä¸ªäºº': 1735,\n",
       "         'æ— èƒ½': 185,\n",
       "         'æ”¿åºœ': 244,\n",
       "         'éœ€è¦': 1821,\n",
       "         'æ±‚åŠ©äº': 4,\n",
       "         'è¿™äº›': 1479,\n",
       "         'æ‰èƒ½': 836,\n",
       "         'è§£å†³': 280,\n",
       "         'éš¾é¢˜': 53,\n",
       "         'ä½“ç°': 435,\n",
       "         'ä»·å€¼': 334,\n",
       "         'æ‰€ä»¥': 2768,\n",
       "         'ç…§æŠ„': 24,\n",
       "         'è¿™ç§': 6498,\n",
       "         'æ¨¡å¼': 481,\n",
       "         'å®é™…ä¸Š': 187,\n",
       "         'é—®é¢˜': 2398,\n",
       "         'æˆ‘ä»¬': 6039,\n",
       "         'ä»¥å‰': 1095,\n",
       "         'å˜²ç¬‘': 88,\n",
       "         'è‹±é›„ä¸»ä¹‰': 283,\n",
       "         'å´': 6254,\n",
       "         'æ²¡æƒ³åˆ°': 937,\n",
       "         'æ†ç»‘': 34,\n",
       "         'çˆ±å›½ä¸»ä¹‰': 87,\n",
       "         'å…¨èƒ½': 17,\n",
       "         'æˆ˜å£«': 112,\n",
       "         'æ›´åŠ ': 722,\n",
       "         'éš¾ä»¥': 482,\n",
       "         'ä¸‹å’½': 11,\n",
       "         'å¤š': 9263,\n",
       "         'æ— è„‘': 258,\n",
       "         'ä¿¡': 223,\n",
       "         'æˆ': 3726,\n",
       "         'å¯¹': 10153,\n",
       "         'å´äº¬è·¯': 1,\n",
       "         'è½¬ç²‰': 31,\n",
       "         'æœ€å': 9967,\n",
       "         'å½©è›‹': 561,\n",
       "         'æ²¡æœ‰': 14757,\n",
       "         'ç†ç”±': 375,\n",
       "         'æœŸå¾…': 1442,\n",
       "         'ä¸‹': 3547,\n",
       "         'ä¸€éƒ¨': 9687,\n",
       "         'å‡': 656,\n",
       "         'å—¨': 215,\n",
       "         'å‡ å¤„': 175,\n",
       "         'æƒ…èŠ‚': 3993,\n",
       "         'è®¾ç½®': 521,\n",
       "         'è¿‡äº': 1024,\n",
       "         'å½°æ˜¾': 67,\n",
       "         'å›½å®¶': 828,\n",
       "         'è‡ªè±ªæ„Ÿ': 5,\n",
       "         'ç¨æ˜¾': 201,\n",
       "         'çªå…€': 390,\n",
       "         'çˆ½ç‰‡': 23,\n",
       "         'æ‰“æˆ': 355,\n",
       "         'æŒºç‡ƒ': 12,\n",
       "         'ä½†æ˜¯': 7721,\n",
       "         'æ•…äº‹': 15005,\n",
       "         'ä¸€èˆ¬': 3549,\n",
       "         'è¾¾åº·': 13,\n",
       "         'ä¹¦è®°': 19,\n",
       "         'åˆé€‚': 297,\n",
       "         'è§’è‰²': 3732,\n",
       "         'èµµ': 45,\n",
       "         'ä¸œæ¥': 11,\n",
       "         'å€’': 1606,\n",
       "         'å¼ ç€š': 6,\n",
       "         'å¤ªå¤ª': 203,\n",
       "         'å¤ªè¿': 15,\n",
       "         'åˆ†é’Ÿ': 1825,\n",
       "         'ç©¿è¶Š': 530,\n",
       "         'å›': 401,\n",
       "         'å¶åƒå‰§': 113,\n",
       "         'ï¼š': 6359,\n",
       "         'æ¥åˆ°': 24,\n",
       "         'éæ´²': 134,\n",
       "         'å§åº•': 189,\n",
       "         'å†·é”‹': 14,\n",
       "         'æŠ¥å‘Š': 26,\n",
       "         'ä¸ä¹‰ç': 6,\n",
       "         'ç°åœ¨': 3750,\n",
       "         'è¯·æ±‚': 13,\n",
       "         'æŠ“æ•': 8,\n",
       "         'æè¾¾åº·': 4,\n",
       "         'è¿™ä»¶': 111,\n",
       "         'äº‹å…ˆ': 24,\n",
       "         'ä¸è¦': 2510,\n",
       "         'å£°å¼ ': 4,\n",
       "         'åˆ«': 732,\n",
       "         'çœå…': 3,\n",
       "         'çŸ¥é“': 5386,\n",
       "         'å°±': 25693,\n",
       "         'ä½ ': 17210,\n",
       "         'ä¸€èµ·': 2807,\n",
       "         'å»': 7304,\n",
       "         'åŠ ä¸Š': 901,\n",
       "         'åŒå¿—': 267,\n",
       "         'ä¸‰äºº': 130,\n",
       "         'é€®æ•': 12,\n",
       "         'è¿™æ¬¡': 940,\n",
       "         'è¡Œ': 1015,\n",
       "         'å«': 2031,\n",
       "         'å§': 10758,\n",
       "         'æ‹': 8200,\n",
       "         'å–œå‰§': 2736,\n",
       "         'æ•´ä¸ª': 1785,\n",
       "         'æ„Ÿè§‰': 8017,\n",
       "         'æŒº': 6253,\n",
       "         'æç¬‘': 2400,\n",
       "         'è¿™ä¹ˆ': 6949,\n",
       "         'æ‰“': 3778,\n",
       "         'è¿‡': 3585,\n",
       "         'å¾æ™“å†¬': 1,\n",
       "         'ä¹ˆ': 3598,\n",
       "         'ï¼Ÿ': 19222,\n",
       "         'å¿ƒå¾€': 3,\n",
       "         'ä¸€å¤„': 76,\n",
       "         'åŠ²å¾€': 3,\n",
       "         'ä½¿': 490,\n",
       "         'æ¢¦æƒ³': 1196,\n",
       "         'çœ‹å§': 159,\n",
       "         'ç¬¬ä¸€éƒ¨': 2316,\n",
       "         'å¥½å¤ªå¤š': 92,\n",
       "         'è°¢è°¢': 239,\n",
       "         'ç¾é˜Ÿ': 126,\n",
       "         'åŠ¨ä½œ': 3388,\n",
       "         'æŒ‡å¯¼': 121,\n",
       "         'è¿™': 17339,\n",
       "         'ç«': 180,\n",
       "         'æ²¡è§è¯†': 5,\n",
       "         'å¼€å¤´': 1341,\n",
       "         'é•¿': 1109,\n",
       "         'å¯¹å†³': 215,\n",
       "         'æˆå¯ç®—': 1,\n",
       "         'åè¯­': 297,\n",
       "         'é¡¶å°–': 29,\n",
       "         'å­˜åœ¨': 1295,\n",
       "         'é©±é€èˆ°': 4,\n",
       "         'å¯¼å¼¹': 25,\n",
       "         'å¦å…‹': 215,\n",
       "         'å•†ä¸šç‰‡': 548,\n",
       "         'ç‹‚ç”¨': 1,\n",
       "         'é•œå¤´': 4296,\n",
       "         'è¿ç”¨': 397,\n",
       "         'ç¬‘': 3755,\n",
       "         'ç‚¹': 3691,\n",
       "         'æ’å…¥': 85,\n",
       "         'å¥½è±å': 1246,\n",
       "         'çˆ†ç±³èŠ±': 567,\n",
       "         'ä¸åŠŸ': 27,\n",
       "         'ä¸è¿‡': 6527,\n",
       "         'ä»å¤´': 338,\n",
       "         'æ‰“åˆ°': 69,\n",
       "         'å°¾': 340,\n",
       "         'æ‹¼': 312,\n",
       "         'è™½ç„¶': 5822,\n",
       "         'æœ‰ç•¥': 4,\n",
       "         'ä¹±': 690,\n",
       "         'æ—¶': 2942,\n",
       "         'å› ä¸º': 4086,\n",
       "         'æ²¡': 11136,\n",
       "         'å•¥': 1874,\n",
       "         'æœŸæœ›å€¼': 56,\n",
       "         'è¢«': 9947,\n",
       "         'å“äº†ä¸€è·³': 10,\n",
       "         'å´åˆš': 10,\n",
       "         'è°¦å’Œ': 6,\n",
       "         'ä¸æµ·å³°': 1,\n",
       "         'è€': 3022,\n",
       "         'ä¸‰ä½': 111,\n",
       "         'ç‚–': 43,\n",
       "         'çƒ‚ç†Ÿ': 8,\n",
       "         'ç‰›ç­‹': 1,\n",
       "         'åš¼': 51,\n",
       "         'ç”¨å¿ƒ': 635,\n",
       "         'å•Š': 20872,\n",
       "         'å¯¼æ¼”': 8669,\n",
       "         'å°çœ‹': 21,\n",
       "         'ç¡®å®': 2168,\n",
       "         'ä¸‹åŠŸå¤«': 27,\n",
       "         'æ‹‰': 404,\n",
       "         'å€Ÿé‰´': 176,\n",
       "         'è‡³äº': 474,\n",
       "         'å¤§å®¶': 1361,\n",
       "         'æ¯”è¾ƒ': 3307,\n",
       "         'åæ„Ÿ': 144,\n",
       "         'æƒ…ç»ª': 1075,\n",
       "         'é‚£äº›': 2407,\n",
       "         'æ¡¥æ®µ': 954,\n",
       "         'å¿…å¤‡': 57,\n",
       "         'ç¨å¾®': 405,\n",
       "         'ä¸€ç‚¹': 2989,\n",
       "         'è¿˜': 17880,\n",
       "         'å¯ä»¥': 8972,\n",
       "         'æ¥å—': 925,\n",
       "         'æœ€å¥½': 1951,\n",
       "         'åœ°æ–¹': 2173,\n",
       "         'æŒæ¡': 151,\n",
       "         'å¼ å¼›': 68,\n",
       "         'æœ‰åº¦': 62,\n",
       "         'è¿™ç‚¹': 283,\n",
       "         'éš¾å¾—': 882,\n",
       "         'ä¸€ç›´': 3317,\n",
       "         'è„‘å­é‡Œ': 62,\n",
       "         'å›å“': 39,\n",
       "         'ç‰‡å¤´': 357,\n",
       "         'æµ·é‡Œ': 23,\n",
       "         'é‚£åœº': 494,\n",
       "         'æˆçœ‹': 22,\n",
       "         'å®Œ': 5015,\n",
       "         'å‘†': 248,\n",
       "         'ä¸‹å»': 878,\n",
       "         'å¤ªå‡': 207,\n",
       "         'æå‰': 195,\n",
       "         'ç¦»åœº': 130,\n",
       "         'å¥½çœ‹': 8060,\n",
       "         'æ¼”æŠ€': 5630,\n",
       "         'æ£’å‘†': 34,\n",
       "         'ç¬¦åˆ': 413,\n",
       "         'åè€Œ': 828,\n",
       "         'æ›´': 6120,\n",
       "         'å·®': 1706,\n",
       "         'è¿™ä¸€': 125,\n",
       "         'æ”¾ä¹‹å››æµ·è€Œçš†å‡†': 3,\n",
       "         'è§„å¾‹': 30,\n",
       "         'åœºé¢': 2288,\n",
       "         'è¶Šåšè¶Š': 10,\n",
       "         'ç„¶è€Œ': 793,\n",
       "         'ä¼´éš': 124,\n",
       "         'ç‰¹æ•ˆ': 1979,\n",
       "         'å‡çº§': 123,\n",
       "         'å™äº‹': 2095,\n",
       "         'å˜å¾—': 605,\n",
       "         'éå¸¸': 4862,\n",
       "         'å‡Œä¹±': 213,\n",
       "         'æ ¼å±€': 339,\n",
       "         'é¢‡': 391,\n",
       "         'æ‹æˆ': 446,\n",
       "         'é»‘é¹°å è½': 30,\n",
       "         'ç»“æœ': 1813,\n",
       "         'æ’‘æ­»': 16,\n",
       "         'æœ€å¤š': 97,\n",
       "         'åªæ˜¯': 4107,\n",
       "         'å®˜æ–¹': 66,\n",
       "         'ç‰ˆ': 2157,\n",
       "         'æ•¢æ­»é˜Ÿ': 64,\n",
       "         'ä½†è®º': 8,\n",
       "         'è‡ªæˆ‘': 769,\n",
       "         'è§’è‰²å®šä½': 15,\n",
       "         'èƒ½åŠ›': 616,\n",
       "         'è¿œ': 381,\n",
       "         'å¦‚åŒ': 318,\n",
       "         'æ¼”å‘˜': 5512,\n",
       "         'å‡ºèº«': 113,\n",
       "         'ç”„å­ä¸¹': 389,\n",
       "         'å–œæ¬¢': 13959,\n",
       "         'ä¸æ˜¯': 8787,\n",
       "         'è£…å‚»': 30,\n",
       "         'çœŸå‚»': 19,\n",
       "         'è¦ä¸æ˜¯': 329,\n",
       "         'çœŸçš„': 7923,\n",
       "         'åˆ«çš„': 445,\n",
       "         'å¯': 2097,\n",
       "         'è‚¯å®š': 756,\n",
       "         'é€‰': 321,\n",
       "         'ç›´ç”·ç™Œ': 59,\n",
       "         'ä»¤äººå‘æŒ‡': 105,\n",
       "         'æ‰€æœ‰': 2058,\n",
       "         'å‰§æƒ…': 11620,\n",
       "         'èµ°å‘': 374,\n",
       "         'ä¹åå¹´ä»£': 112,\n",
       "         'é‚£å¥—': 56,\n",
       "         'ç…§æ¬': 101,\n",
       "         'å®¡ç¾': 269,\n",
       "         'äº‹å„¿': 324,\n",
       "         'ä¸€æ—¶åŠä¼šå„¿': 2,\n",
       "         'åŸ¹å…»': 50,\n",
       "         'å‡ºæ¥': 3402,\n",
       "         'æ•´éƒ¨': 1077,\n",
       "         'å»¶ç»­': 368,\n",
       "         'é£æ ¼': 2812,\n",
       "         'çƒ­è¡€': 762,\n",
       "         'æ¯”æ¥': 1,\n",
       "         'è¦': 8115,\n",
       "         'ä¸é”™': 10613,\n",
       "         'é€‚åˆ': 1841,\n",
       "         'æ¼”': 3457,\n",
       "         'å†›äºº': 81,\n",
       "         'ä¹‹å‰': 1517,\n",
       "         'ç‰‡æ®µ': 555,\n",
       "         'å¿µ': 131,\n",
       "         'åŠ²å„¿': 131,\n",
       "         'æ¥è¯´': 1554,\n",
       "         'å¼ ç¿°å¤ªè¿': 1,\n",
       "         'ä¸€': 3708,\n",
       "         'ä¸€è‚¡': 327,\n",
       "         'é›·é˜µé›¨': 3,\n",
       "         'ç”»é£': 450,\n",
       "         'ç›®çªç‹—': 2,\n",
       "         'ç˜ è–„': 3,\n",
       "         'äººç‰›': 5,\n",
       "         'ç¡¬é“ç†': 18,\n",
       "         'éš”å£': 128,\n",
       "         'å»ºå†›': 6,\n",
       "         'å¤§çˆ·': 196,\n",
       "         'ä½ ä»¬': 1877,\n",
       "         'åœºæ™¯': 1666,\n",
       "         'æˆ˜æ–—': 355,\n",
       "         'å…¨çº¿': 14,\n",
       "         'æ‰“æ–—': 1162,\n",
       "         'æ¸¸èµ°': 49,\n",
       "         'å®¡æŸ¥': 133,\n",
       "         'çº¢çº¿': 12,\n",
       "         'è¾¹ç•Œ': 27,\n",
       "         'æ”¿æ²»': 1053,\n",
       "         'å®‰å…¨': 124,\n",
       "         'ç¼éš™': 17,\n",
       "         'éƒ¨': 720,\n",
       "         'æå…·': 157,\n",
       "         'ç…½åŠ¨': 33,\n",
       "         'å¤§ç‰‡': 1043,\n",
       "         'åˆ¶ä½œ': 1223,\n",
       "         'ç²¾è‰¯': 215,\n",
       "         'å½±ç‰‡': 4879,\n",
       "         'è¯·': 958,\n",
       "         'å¤šæ¥': 7,\n",
       "         'èƒ¶å·': 18,\n",
       "         'æŒºå·®': 9,\n",
       "         'è¿‡åº¦': 269,\n",
       "         'éƒ¨é˜Ÿ': 81,\n",
       "         'æ²¡å¤ªå¤š': 38,\n",
       "         'å±•ç¤º': 353,\n",
       "         'æ­»å»': 247,\n",
       "         'åæ­£': 625,\n",
       "         'å¸å¼•': 807,\n",
       "         'å†²': 253,\n",
       "         'ä¸ºä»€ä¹ˆ': 3237,\n",
       "         'é„™è§†': 87,\n",
       "         'æ•¢': 350,\n",
       "         'å¼€æ‹“': 23,\n",
       "         'å…è®¸': 69,\n",
       "         'ä»–ä»¬': 3131,\n",
       "         'å†': 5342,\n",
       "         'ç›´åˆ°': 337,\n",
       "         'æ›´å¥½': 1000,\n",
       "         'æ‹å‡º': 576,\n",
       "         'æ£’': 1010,\n",
       "         'å‡ºå½©': 1005,\n",
       "         'å‘¢': 4505,\n",
       "         'ç«çˆ†': 196,\n",
       "         'æœ¬ç‰‡': 1954,\n",
       "         'å¿…å°†': 38,\n",
       "         'ç‡ƒçˆ†': 59,\n",
       "         'æš‘æœŸ': 54,\n",
       "         'å‰å®³': 851,\n",
       "         'èº«ä¸º': 125,\n",
       "         'æ­¦æ‰“': 320,\n",
       "         'é«˜æ ‡å‡†': 3,\n",
       "         'æªæˆ˜': 696,\n",
       "         'ä¸º': 4910,\n",
       "         'ç‚¹èµ': 112,\n",
       "         'çƒ­è¡€ç”·å„¿': 2,\n",
       "         'è·å°”è’™': 159,\n",
       "         'çˆ†å‘': 407,\n",
       "         'ç»™': 10403,\n",
       "         'æ˜Ÿ': 2239,\n",
       "         'è¡€æˆ˜': 39,\n",
       "         'é’¢é”¯': 19,\n",
       "         'å²­': 34,\n",
       "         'ä¼š': 7743,\n",
       "         'æ­Œé¢‚': 74,\n",
       "         'å®—æ•™': 719,\n",
       "         'æƒ…æ€€': 962,\n",
       "         'è¶…è¶Š': 579,\n",
       "         'æ”¿æƒ': 33,\n",
       "         'å½“': 2871,\n",
       "         'åª': 3341,\n",
       "         'æ˜æ˜¾': 1200,\n",
       "         'ä½': 753,\n",
       "         'å±‚æ¬¡': 173,\n",
       "         'å……æ»¡': 1393,\n",
       "         'ç°å®': 2248,\n",
       "         'ä¹ƒè‡³': 76,\n",
       "         'æŠ•æœº': 29,\n",
       "         'è€ƒé‡': 29,\n",
       "         'é«˜ä¸‹': 49,\n",
       "         'ç«‹': 91,\n",
       "         'è§': 744,\n",
       "         'è¯·é—®': 99,\n",
       "         'å´äº¬è„‘': 3,\n",
       "         'æ®‹': 142,\n",
       "         'ç«ç®­ç‚®': 6,\n",
       "         'å—': 4971,\n",
       "         'å‚²æ°”': 6,\n",
       "         'é›„é¹°': 3,\n",
       "         'ç¬¬ä¸€': 532,\n",
       "         'æ»´è¡€': 26,\n",
       "         'ç®—æ˜¯': 1689,\n",
       "         'å›½å†…': 510,\n",
       "         'ç‰‡': 6649,\n",
       "         'å‡†': 48,\n",
       "         'é’±': 942,\n",
       "         'èŠ±': 437,\n",
       "         'æœ‰æ•ˆ': 62,\n",
       "         'æ°”é­„': 22,\n",
       "         'åˆ›ä½œ': 266,\n",
       "         'è¶³å¤Ÿ': 607,\n",
       "         'çœŸè¯š': 293,\n",
       "         'äººç‰©': 3996,\n",
       "         'è¿': 1644,\n",
       "         'å¼ ç¿°': 38,\n",
       "         'å¯çˆ±': 3116,\n",
       "         'å¦‚æœ': 3615,\n",
       "         'å½“å¹´': 1479,\n",
       "         'é‚£æ ·': 1074,\n",
       "         'ä¸€æ—¶': 103,\n",
       "         'è†¨èƒ€': 34,\n",
       "         'é“¶å¹•': 474,\n",
       "         'ç‹¬å ': 5,\n",
       "         'èšå…‰ç¯': 9,\n",
       "         'èµ°': 1813,\n",
       "         'æ‰ªå¿ƒè‡ªé—®': 8,\n",
       "         'æ²¡æ³•': 383,\n",
       "         'è¯„ä»·': 589,\n",
       "         'å…¨ç‰‡': 1218,\n",
       "         'é ': 1179,\n",
       "         'æˆæ’‘': 2,\n",
       "         'æ–‡æˆ': 309,\n",
       "         'æ‰¯æ·¡': 253,\n",
       "         'å¥³ä¸»è§’': 1429,\n",
       "         'æ¯«æ— ': 1353,\n",
       "         'å¿…è¦': 476,\n",
       "         'åªè¦': 716,\n",
       "         'å¼€æŒ‚': 105,\n",
       "         'ç‰›': 1633,\n",
       "         'é€¼': 3647,\n",
       "         'ä¹‹å¤„': 119,\n",
       "         'åœ¨äº': 671,\n",
       "         'é€éœ²': 122,\n",
       "         'æ': 239,\n",
       "         'å¼ºçƒˆ': 550,\n",
       "         'æ„è¯†å½¢æ€': 117,\n",
       "         'æ·é”': 32,\n",
       "         'ç¥–å›½': 67,\n",
       "         'é¢å‰': 408,\n",
       "         'ä¸€åˆ‡': 1961,\n",
       "         'ååŠ¨æ´¾': 5,\n",
       "         'çº¸è€è™': 13,\n",
       "         'äººå¼€': 3,\n",
       "         'æŒ‚': 276,\n",
       "         'å›¢ç­': 13,\n",
       "         'åˆæƒ…åˆç†': 33,\n",
       "         'ä¸¤æ˜Ÿ': 745,\n",
       "         'é¼“åŠ±': 469,\n",
       "         'å…¶ä»–': 1757,\n",
       "         'ä¸€èˆ¬èˆ¬': 484,\n",
       "         'çœ‹ç‚¹': 515,\n",
       "         'æœ‰ç‚¹': 7674,\n",
       "         'æ‰‹æ¥': 2,\n",
       "         'å“ˆå“ˆå“ˆ': 1637,\n",
       "         'ä»': 4309,\n",
       "         'ä¹‹å': 2323,\n",
       "         'ç‚¸': 211,\n",
       "         'ç¿»': 272,\n",
       "         'ä¸€ä¸‹': 1818,\n",
       "         'å››æ˜Ÿ': 1122,\n",
       "         'å½“æ—¶': 1066,\n",
       "         'å…¶å®': 5782,\n",
       "         'å®Œæˆåº¦': 199,\n",
       "         'æ¥è¿‘': 310,\n",
       "         'æ¯ä¸ª': 2145,\n",
       "         'æ­¥éª¤': 8,\n",
       "         'é¡ºæ»‘': 6,\n",
       "         'ä»»ä½•': 1177,\n",
       "         'å‡ºäººæ„æ–™': 76,\n",
       "         'æ˜¯å› ä¸º': 882,\n",
       "         'çœ‹çœ‹': 1632,\n",
       "         'æœ€è¿‘': 763,\n",
       "         'ä¸–ç•Œ': 3435,\n",
       "         'æŠ±æ­‰': 76,\n",
       "         'å½±é™¢': 788,\n",
       "         'ç‡ƒ': 183,\n",
       "         'èµ·æ¥': 2043,\n",
       "         'é­”å¹»': 378,\n",
       "         'å½“ç„¶': 1233,\n",
       "         'å¼ºæ‹†': 38,\n",
       "         'ç°å®æ„Ÿ': 16,\n",
       "         'ä¸€å¹•': 481,\n",
       "         'å¼€åœº': 457,\n",
       "         'ææ–—': 38,\n",
       "         'ä»æ¥': 312,\n",
       "         'å…¶å®ƒ': 192,\n",
       "         'æ‹æ‘„': 964,\n",
       "         'éš¾åº¦': 72,\n",
       "         'åŒæ—¶': 732,\n",
       "         'æŠ€èƒ½': 81,\n",
       "         'æ–¹é¢': 809,\n",
       "         'è¦æ±‚': 318,\n",
       "         'å›æ¥': 523,\n",
       "         'æœ': 51,\n",
       "         'å´äº¬ä¼š': 1,\n",
       "         'æ¸¸æ³³': 37,\n",
       "         'æ½œæ°´': 9,\n",
       "         'æ»‘é›ª': 14,\n",
       "         'å¼€': 517,\n",
       "         'é£æœº': 553,\n",
       "         'å°„å‡»': 41,\n",
       "         'å„é¡¹': 6,\n",
       "         'ç‰¹æ„': 108,\n",
       "         'ç‰¹ç§éƒ¨é˜Ÿ': 36,\n",
       "         'å½“è¿‡': 7,\n",
       "         'æœˆ': 460,\n",
       "         'å…µ': 46,\n",
       "         'ä½©æœ': 344,\n",
       "         'è¿™æ ·': 6673,\n",
       "         'æ˜ŸåŠ': 174,\n",
       "         'ç»“æŸ': 893,\n",
       "         'æŒå£°': 52,\n",
       "         'å‡ºç°': 1635,\n",
       "         'è¿‘æœŸ': 118,\n",
       "         'å°‘è§': 111,\n",
       "         'ä¸€ç²’': 17,\n",
       "         'å¤§è¡¥ä¸¸': 1,\n",
       "         'æœ‰äºº': 940,\n",
       "         'åƒ': 1258,\n",
       "         'å¼€å¿ƒ': 775,\n",
       "         'è¡¥å¤§': 1,\n",
       "         'ä»ç™½': 1,\n",
       "         'é»‘': 1012,\n",
       "         'å­—å¹•': 770,\n",
       "         'å±•ç°': 668,\n",
       "         'è¶…çº§': 1301,\n",
       "         'ç›´': 233,\n",
       "         'ç”·': 1876,\n",
       "         'ç³™': 67,\n",
       "         'çŒ›': 132,\n",
       "         'åª²ç¾': 80,\n",
       "         'ç»ˆç»“è€…': 69,\n",
       "         'æ— äº®ç‚¹': 65,\n",
       "         'å¼ ç¿°å˜': 1,\n",
       "         'è°æ˜Ÿ': 25,\n",
       "         'æŒæ§': 194,\n",
       "         'é€¼è¿‘': 26,\n",
       "         'ä¸ä½': 213,\n",
       "         'è¾¹ç¼˜': 168,\n",
       "         'å¸¦æ„Ÿ': 178,\n",
       "         'æ‹³æ‹³': 105,\n",
       "         'è‚‰': 293,\n",
       "         'è¶…çˆ½': 13,\n",
       "         'èªæ˜': 349,\n",
       "         'é¸¡': 166,\n",
       "         'è´¼': 87,\n",
       "         'ä¸€é¢': 296,\n",
       "         'æ——ä¸‹': 9,\n",
       "         'å‘ˆç°': 436,\n",
       "         'ä¸€å‡º': 296,\n",
       "         'é‡å·¥ä¸š': 4,\n",
       "         'å¨±ä¹': 507,\n",
       "         'è°ƒæ§': 9,\n",
       "         'è¯´æ•™': 316,\n",
       "         'æ¯”ä¾‹': 43,\n",
       "         'å°ºåº¦': 197,\n",
       "         'å¤§ä¼—': 203,\n",
       "         'æ¥çº³': 26,\n",
       "         'æŠŠæ¡': 368,\n",
       "         'å¾®å¦™': 226,\n",
       "         'å…¶ä¸­': 759,\n",
       "         'ä¸€äº›': 2104,\n",
       "         'å¥‡ä¾ ': 9,\n",
       "         'åŒ–': 628,\n",
       "         'å†…å®¹': 1015,\n",
       "         'æ¯”å¦‚': 613,\n",
       "         'ç»ç’ƒç¢´': 2,\n",
       "         'å­å½“': 1,\n",
       "         'é£é•–': 14,\n",
       "         'æ€æ•Œ': 10,\n",
       "         'ä¸€ç±»': 108,\n",
       "         'åªä¸è¿‡': 325,\n",
       "         'é®ç›–': 13,\n",
       "         'æ‰': 688,\n",
       "         'è€çˆ¹': 81,\n",
       "         'æ¼”è¿‡': 74,\n",
       "         'ç¾å‰§': 80,\n",
       "         'æå‡»': 76,\n",
       "         'ç‹å›½': 47,\n",
       "         'åŠ›è': 107,\n",
       "         'é‚£éƒ¨': 123,\n",
       "         'ä¸ºå•¥': 477,\n",
       "         'å¥‡å¼‚': 83,\n",
       "         'æ©å…¸': 2,\n",
       "         'é…ä¹': 2810,\n",
       "         'ç”»å†…': 1,\n",
       "         'ç”·ç”Ÿ': 186,\n",
       "         'çš„è¯': 1393,\n",
       "         'åº”è¯¥': 3298,\n",
       "         'åˆºæ¿€': 630,\n",
       "         'è‚¾ä¸Šè…ºç´ ': 67,\n",
       "         'å¥³ç”Ÿ': 334,\n",
       "         'å¯¹é¾™å°äº‘': 1,\n",
       "         'æ„Ÿæƒ…': 1738,\n",
       "         'ååˆ†': 830,\n",
       "         'æ‰“åŠ¨': 598,\n",
       "         'æ¨¡ä»¿': 570,\n",
       "         'è®¸å¤š': 551,\n",
       "         'æ€ä¹ˆ': 4816,\n",
       "         'ç©': 1231,\n",
       "         'ä¸€è‚¡è„‘': 15,\n",
       "         'å †': 40,\n",
       "         'æ§½': 584,\n",
       "         'å‡ ä½': 177,\n",
       "         'è¡€åšåˆ°': 1,\n",
       "         'ç§‘å¹»': 699,\n",
       "         'çº§åˆ«': 187,\n",
       "         'é‡å¤': 359,\n",
       "         'æ»¡è¡€': 15,\n",
       "         'çº¢è¡€': 1,\n",
       "         'ä¸­æ¯’': 17,\n",
       "         'æé€Ÿ': 34,\n",
       "         'å›è¡€': 5,\n",
       "         'çˆ†ç§': 3,\n",
       "         'æ‰“é€š': 14,\n",
       "         'å…¨åœº': 345,\n",
       "         '...': 5709,\n",
       "         'å¤ªè¿‡': 616,\n",
       "         'æŠ•æœºå–å·§': 10,\n",
       "         'ç©¿': 515,\n",
       "         'è¿ˆå…‹å°”': 84,\n",
       "         'è´éƒ½': 1,\n",
       "         'ä¸å—': 10,\n",
       "         'å¾…è§': 65,\n",
       "         'å›½ç‰‡': 19,\n",
       "         'å‰ä»†åç»§': 9,\n",
       "         'çˆ†ç‚¸': 371,\n",
       "         'å‡çç‡ƒ': 1,\n",
       "         'æ²¡ç”¨': 136,\n",
       "         'å¥³äºº': 2372,\n",
       "         'ç¼º': 169,\n",
       "         'ç”·äºº': 2387,\n",
       "         'å¾æœ': 75,\n",
       "         'å´äº¬ç›´': 1,\n",
       "         'ç”·ç™Œ': 34,\n",
       "         'ğŸ‡¨': 1,\n",
       "         'ğŸ‡³': 1,\n",
       "         'ç¾å›½': 2622,\n",
       "         'ä¸è¡Œ': 1066,\n",
       "         'æ­»': 3846,\n",
       "         'å…¨éƒ½': 247,\n",
       "         'è·³': 489,\n",
       "         'è·Ÿ': 4141,\n",
       "         'è·³å¢™': 3,\n",
       "         'ä¸€æ ·': 4728,\n",
       "         'æ‹¯æ•‘': 678,\n",
       "         'å›½äº§ç‰‡': 358,\n",
       "         'ä»¥': 1947,\n",
       "         'ä¸­å°': 3,\n",
       "         'å±€åŠ¿': 11,\n",
       "         'å¯¹æ¯”': 464,\n",
       "         'å‡æƒ³': 8,\n",
       "         'çœŸæ˜¯': 6452,\n",
       "         'è®½åˆº': 765,\n",
       "         'è°„åªš': 19,\n",
       "         'å†›æ—…': 11,\n",
       "         'é¢˜æ': 2764,\n",
       "         'è´¨æ„Ÿ': 370,\n",
       "         'ç‡ƒåˆ°': 34,\n",
       "         'å›½å¤–': 150,\n",
       "         'ç²¾å½©': 2853,\n",
       "         'çœ‹ç€': 1895,\n",
       "         'æœ‰åŠ›': 225,\n",
       "         'å¿…é¡»': 698,\n",
       "         'å®‰åˆ©': 43,\n",
       "         'ä¸€ä¸‹å¼ ': 2,\n",
       "         'ç¿°': 3,\n",
       "         'ç®€ç›´': 2429,\n",
       "         'æ‰¿åŒ…': 27,\n",
       "         'ç¬‘ç‚¹': 1117,\n",
       "         'é‡èº«å®šåš': 34,\n",
       "         'å½­äº': 225,\n",
       "         'æ™': 205,\n",
       "         'å¯æ¼”': 6,\n",
       "         'ä¸æ¥': 66,\n",
       "         'ä¸å°‘': 1113,\n",
       "         'æ¼‚ç§»': 19,\n",
       "         'æ— äººæœº': 41,\n",
       "         'çªè¢­': 59,\n",
       "         'ç›´å‡æœº': 68,\n",
       "         'å éœ²': 2,\n",
       "         'è‚‰æ': 96,\n",
       "         'å†›èˆ°': 13,\n",
       "         'å‘å°„': 18,\n",
       "         'å›ä¹±': 4,\n",
       "         'å›½é™…åŒ–': 22,\n",
       "         'è§†è§’': 778,\n",
       "         'æ ‡é…': 55,\n",
       "         'é¥°æ¼”': 260,\n",
       "         'æ·±å…¥äººå¿ƒ': 49,\n",
       "         'æå‘½': 41,\n",
       "         'ç²¾ç¥': 990,\n",
       "         'å½“ä¸‹': 254,\n",
       "         'ç¬¬ä¸‰éƒ¨': 309,\n",
       "         'å¥½ç‡ƒ': 17,\n",
       "         'è¡¨ç™½': 124,\n",
       "         'å…¸å‹': 889,\n",
       "         'æ–¹å¼': 1254,\n",
       "         'æ¯æ¬¡': 638,\n",
       "         'çŒœ': 553,\n",
       "         'æ²¡åŠ²': 224,\n",
       "         'è¯¶': 271,\n",
       "         '~': 21638,\n",
       "         'é—®': 421,\n",
       "         'ç‹ç‰Œ': 84,\n",
       "         'ç‰¹å·¥': 401,\n",
       "         'é‚£ä¹ˆ': 6596,\n",
       "         'æ€äºº': 526,\n",
       "         'ç»è¿‡': 190,\n",
       "         'è‰ºæœ¯': 696,\n",
       "         'å¤„ç†': 1053,\n",
       "         'ç›´æ¥': 1102,\n",
       "         'åˆ ': 126,\n",
       "         'è¡€è…¥': 585,\n",
       "         'å± æ€': 63,\n",
       "         'èµ¤è£¸è£¸': 113,\n",
       "         'å¤§æ®µ': 149,\n",
       "         'æ­£ç¡®': 300,\n",
       "         'åº‡è¡£': 1,\n",
       "         'æ„æ–™ä¹‹ä¸­': 88,\n",
       "         'æ„æ–™ä¹‹å¤–': 67,\n",
       "         'æƒŠå–œ': 1335,\n",
       "         'å±äº': 748,\n",
       "         'ç‹¼æ€§': 4,\n",
       "         'å†›é­‚': 2,\n",
       "         'å‡ ä¸ª': 1927,\n",
       "         'ç½‘çº¢æ‹‰': 1,\n",
       "         'å¼¹å¼¹ç´': 2,\n",
       "         'å¤§å›½': 36,\n",
       "         'æ°”è±¡': 12,\n",
       "         'æ»¡å±': 79,\n",
       "         'è¿™æ‰': 554,\n",
       "         'å‘Šè¯‰': 936,\n",
       "         'å´': 104,\n",
       "         'è¿ªå¡å°”': 58,\n",
       "         'å¦‚å…¥æ— äººä¹‹å¢ƒ': 4,\n",
       "         'äº¿': 75,\n",
       "         'å¤§é™†': 716,\n",
       "         'ä¸€åˆ»': 195,\n",
       "         'é›†ä½“': 273,\n",
       "         'å‹ƒèµ·': 11,\n",
       "         'ç¦»å¼€': 469,\n",
       "         'å½±å…': 27,\n",
       "         'å±Œä¸': 381,\n",
       "         'åŒæ ·': 867,\n",
       "         'å¼€å§‹': 3353,\n",
       "         'å‰': 2745,\n",
       "         ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 125794\n"
     ]
    }
   ],
   "source": [
    "print('Total words',len(word_count))\n",
    "\n",
    "vocab_size = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_word = {}\n",
    "id_to_word[0] = '<PAD>'\n",
    "\n",
    "sort_word_fre = sorted(word_count,key=word_count.get,reverse=True)\n",
    "\n",
    "for i,w in enumerate(sort_word_fre[:vocab_size],1):id_to_word[i] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_id = {w:i for i,w in id_to_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sequence(word_sequence,maxlength):\n",
    "    pad_sequence = np.zeros((len(word_sequence),maxlength),dtype=np.int32)\n",
    "    for ri,row in enumerate(word_sequence):\n",
    "        for ci,w in enumerate(row.split()[:maxlength]):\n",
    "            pad_sequence[ri,ci] = word_to_id.get(w,0)\n",
    "    return pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence = pad_sequence(movie_comments['word_sequence'],200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "star = movie_comments['star'].values\n",
    "star = star.astype(np.int32)\n",
    "sub_one = np.vectorize(lambda x:x-1)\n",
    "star = sub_one(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u,c = np.unique(star,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09393332160584947\n",
      "1 0.10759711503896839\n",
      "2 0.2511415175874016\n",
      "3 0.3204968374035351\n",
      "4 0.22683120836424545\n"
     ]
    }
   ],
   "source": [
    "for s,n in zip(u,c):print(s,n/sum(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot_star = np.eye(5,dtype=np.int32)[star]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sequence_batches(datasets,labels,batch_size):\n",
    "    assert datasets.shape[0] == labels.shape[0]\n",
    "    batch_num = datasets.shape[0] // batch_size\n",
    "    datasets_cut = datasets[:batch_num*batch_size,:]\n",
    "    last_datasets = datasets[batch_num*batch_size:,:]\n",
    "    labels_cut = labels[:batch_num*batch_size,:]\n",
    "    last_labels = labels[batch_num*batch_size:,:]\n",
    "    \n",
    "    for i in range(batch_num+1):\n",
    "        if i == batch_num:\n",
    "            #yield last_datasets,last_labels\n",
    "            break\n",
    "        x = datasets_cut[i*batch_size:(i+1)*batch_size,:]\n",
    "        y = labels_cut[i*batch_size:(i+1)*batch_size,:]\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (209195, 200)\n",
      "val_x shape: (26149, 200)\n",
      "test_x shape: (26150, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "sequence,onehot_star = shuffle(sequence,onehot_star,random_state=42)\n",
    "\n",
    "split_idx = int(len(sequence)*0.8)\n",
    "\n",
    "train_x, val_x = sequence[:split_idx], sequence[split_idx:]\n",
    "train_y, val_y = onehot_star[:split_idx], onehot_star[split_idx:]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('val_x shape:', val_x.shape)\n",
    "print('test_x shape:', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_feature = 200\n",
    "embed_size = 300\n",
    "lstm_size = 32\n",
    "lstm_layers = 2\n",
    "dropout_rate = 0.5\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load embeddings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('./cc.zh.300.vec')\n",
    "\n",
    "count_not_in_pretrain = 0\n",
    "word_not_in_pretrain = []\n",
    "np.random.seed(42)\n",
    "pretrianed_wv = np.random.uniform(-1,1,(vocab_size+1,embed_size))\n",
    "for word,idx in word_to_id.items():\n",
    "    if word not in word_vectors:\n",
    "        count_not_in_pretrain += 1\n",
    "        word_not_in_pretrain.append(word)\n",
    "        continue\n",
    "    pretrianed_wv[idx] = word_vectors[word]\n",
    "\n",
    "print(pretrianed_wv.shape)\n",
    "\n",
    "del word_vectors\n",
    "\n",
    "pretrianed_wv.dump('./pretrained_wv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrianed_wv = np.load('./pretrained_wv.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(word_not_in_pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('word not in pretrained vocab: %.2f' % (count_not_in_pretrain/vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code for sentimental analysis(construct model keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input,Embedding,Dense,CuDNNLSTM,LSTM,Bidirectional,Lambda,dot,Activation,concatenate,Dropout,Masking\n",
    "from keras.models import Model,Sequential\n",
    "from keras.optimizers import adam\n",
    "from keras.initializers import Constant\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', min_delta=0.00005, patience=3, verbose=0,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_3d_blocks(hidden_states,max_feature=200,attention_size=128):\n",
    "    hidden_size = int(hidden_states.shape[2])\n",
    "    score_first_part = Dense(hidden_size, use_bias=False, name='attention_score_vec')(hidden_states)\n",
    "    h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state')(hidden_states)\n",
    "    score = dot([score_first_part, h_t], [2, 1], name='attention_score')\n",
    "    attention_weights = Activation('softmax', name='attention_weight')(score)\n",
    "    context_vector = dot([hidden_states, attention_weights], [1, 1], name='context_vector')\n",
    "    pre_activation = concatenate([context_vector, h_t], name='attention_output')\n",
    "    attention_vector = Dense(attention_size, use_bias=False, activation='tanh',name='attention_vector')(pre_activation)\n",
    "\n",
    "    return attention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(max_feature,))\n",
    "\n",
    "\n",
    "weights = Constant(value=pretrianed_wv)\n",
    "embed_layer = Embedding(vocab_size+1,embed_size,embeddings_initializer=weights)\n",
    "embed_layer.trainable = True\n",
    "\n",
    "embed = embed_layer(inputs)\n",
    "#embed = Masking(mask_value=pretrianed_wv[0])(embed)\n",
    "\n",
    "biLSTM_layer1 = Bidirectional(CuDNNLSTM(lstm_size,return_sequences=True,kernel_regularizer=l2(0.002),recurrent_regularizer=l2(0.002)))(embed)\n",
    "biLSTM_layer1 = Dropout(dropout_rate)(biLSTM_layer1)\n",
    "\n",
    "biLSTM_layer2 = Bidirectional(CuDNNLSTM(lstm_size,return_sequences=True,kernel_regularizer=l2(0.002),recurrent_regularizer=l2(0.002)))(biLSTM_layer1)\n",
    "biLSTM_layer2 = Dropout(dropout_rate)(biLSTM_layer2)\n",
    "\n",
    "\n",
    "attention_mul = attention_3d_blocks(biLSTM_layer2)\n",
    "\n",
    "out_ = Dense(5, activation='softmax')(attention_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     18000300    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 200, 64)      85504       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200, 64)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 200, 64)      25088       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200, 64)      0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_score_vec (Dense)     (None, 200, 64)      4096        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "last_hidden_state (Lambda)      (None, 64)           0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_score (Dot)           (None, 200)          0           attention_score_vec[0][0]        \n",
      "                                                                 last_hidden_state[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "attention_weight (Activation)   (None, 200)          0           attention_score[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "context_vector (Dot)            (None, 64)           0           dropout_2[0][0]                  \n",
      "                                                                 attention_weight[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_output (Concatenate)  (None, 128)          0           context_vector[0][0]             \n",
      "                                                                 last_hidden_state[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "attention_vector (Dense)        (None, 128)          16384       attention_output[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            645         attention_vector[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 18,132,017\n",
      "Trainable params: 18,132,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = Model(inputs=inputs,outputs=out_)\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=opt,\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 209195 samples, validate on 26149 samples\n",
      "Epoch 1/50\n",
      "209195/209195 [==============================] - 1930s 9ms/step - loss: 1.3375 - acc: 0.4383 - val_loss: 1.2284 - val_acc: 0.4650\n",
      "Epoch 2/50\n",
      "209195/209195 [==============================] - 1928s 9ms/step - loss: 1.1549 - acc: 0.5077 - val_loss: 1.2117 - val_acc: 0.4825\n",
      "Epoch 3/50\n",
      "209195/209195 [==============================] - 1922s 9ms/step - loss: 1.0819 - acc: 0.5489 - val_loss: 1.2277 - val_acc: 0.4823\n",
      "Epoch 4/50\n",
      " 13184/209195 [>.............................] - ETA: 29:05 - loss: 0.9681 - acc: 0.6056"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-656a7cbac44e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                              \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                              verbose=1)\n\u001b[0m",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = sentiment_model.fit(train_x,train_y,batch_size=batch_size,\n",
    "                             epochs=epochs,\n",
    "                              callbacks=callbacks,\n",
    "                             validation_data=(val_x,val_y),\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26150/26150 [==============================] - 13s 507us/step\n",
      "Test score: 1.5843035610136977\n",
      "Test accuracy 0.5173996175931015\n"
     ]
    }
   ],
   "source": [
    "score,acc = sentiment_model.evaluate(test_x,test_y,\n",
    "                                    batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "\n",
    "print('Test accuracy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_model.save_weights('./checkpoints/keras_biatten_w.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, concatenate, Activation\n",
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcnn_inputs = Input(shape=(max_feature,))\n",
    "\n",
    "\n",
    "\n",
    "weights = Constant(value=pretrianed_wv)\n",
    "embed_layer = Embedding(vocab_size+1,embed_size,embeddings_initializer=weights)\n",
    "embed_layer.trainable = True\n",
    "\n",
    "embed = embed_layer(inputs)\n",
    "\n",
    "bigram_branch = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(embed)\n",
    "bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "bigram_branch = Dropout(dropout_rate)(bigram_branch)\n",
    "\n",
    "trigram_branch = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(embed)\n",
    "trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "trigram_branch = Dropout(dropout_rate)(trigram_branch)\n",
    "\n",
    "fourgram_branch = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(embed)\n",
    "fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "fourgram_branch = Dropout(dropout_rate)(fourgram_branch)\n",
    "\n",
    "\n",
    "merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "merged = Dense(256, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "outmerge = Dense(5,activation='softmax')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 200)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     18000300    masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 199, 100)     60100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 198, 100)     90100       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 197, 100)     120100      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 100)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 100)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 100)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100)          400         global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100)          400         global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100)          400         global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 300)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 300)          1200        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            1285        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 18,352,365\n",
      "Trainable params: 18,350,653\n",
      "Non-trainable params: 1,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tcnn_model = Model(inputs=tcnn_inputs,outputs=outmerge)\n",
    "tcnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcnn_model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=opt,\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 209195 samples, validate on 26149 samples\n",
      "Epoch 1/50\n",
      "209195/209195 [==============================] - 325s 2ms/step - loss: 1.3430 - acc: 0.4000 - val_loss: 3.7954 - val_acc: 0.3342\n",
      "Epoch 2/50\n",
      "209195/209195 [==============================] - 321s 2ms/step - loss: 1.1804 - acc: 0.4793 - val_loss: 2.0329 - val_acc: 0.2767\n",
      "Epoch 3/50\n",
      "209195/209195 [==============================] - 321s 2ms/step - loss: 1.0769 - acc: 0.5368 - val_loss: 2.9755 - val_acc: 0.2974\n",
      "Epoch 4/50\n",
      "209195/209195 [==============================] - 318s 2ms/step - loss: 0.9732 - acc: 0.5922 - val_loss: 5.2486 - val_acc: 0.3677\n",
      "Epoch 5/50\n",
      "209195/209195 [==============================] - 318s 2ms/step - loss: 0.8755 - acc: 0.6411 - val_loss: 1.6451 - val_acc: 0.4565\n",
      "Epoch 6/50\n",
      "209195/209195 [==============================] - 318s 2ms/step - loss: 0.7936 - acc: 0.6786 - val_loss: 1.6011 - val_acc: 0.4692\n",
      "Epoch 7/50\n",
      "209195/209195 [==============================] - 318s 2ms/step - loss: 0.7216 - acc: 0.7098 - val_loss: 1.3733 - val_acc: 0.5002\n",
      "Epoch 8/50\n",
      "209195/209195 [==============================] - 318s 2ms/step - loss: 0.6657 - acc: 0.7325 - val_loss: 1.3303 - val_acc: 0.5104\n",
      "Epoch 9/50\n",
      "114848/209195 [===============>..............] - ETA: 2:21 - loss: 0.6037 - acc: 0.7610"
     ]
    }
   ],
   "source": [
    "history_cnn = tcnn_model.fit(train_x,train_y,batch_size=batch_size,\n",
    "                             epochs=epochs,\n",
    "                              callbacks=callbacks,\n",
    "                             validation_data=(val_x,val_y),\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26150/26150 [==============================] - 4s 157us/step\n",
      "Test score: 1.9522584938501537\n",
      "Test accuracy 0.5313575525824016\n"
     ]
    }
   ],
   "source": [
    "score,acc = tcnn_model.evaluate(test_x,test_y,\n",
    "                                    batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "\n",
    "print('Test accuracy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcnn_model.save_weights('./checkpoints/keras_tcnn_w.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code for sentimental analysis(construct model tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob_rate = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_graph = tf.Graph()\n",
    "\n",
    "with sentiment_graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.int32, [None,None], name='inputs')\n",
    "    labels_ = tf.placeholder(tf.int32, [None,None], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with sentiment_graph.as_default():\n",
    "    embedding = tf.get_variable(name='embedding',shape=pretrianed_wv.shape,\n",
    "                                initializer=tf.constant_initializer(pretrianed_wv),\n",
    "                               trainable=False)\n",
    "    embed_ = tf.nn.embedding_lookup(embedding,inputs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with sentiment_graph.as_default():\n",
    "    def build_cell(lstm_size,keep_prob):\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size,keep_prob) for _ in range(lstm_layers)])\n",
    "    \n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    outputs , final_state = tf.nn.dynamic_rnn(cell,embed_,\n",
    "                                             initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with sentiment_graph.as_default():\n",
    "    logits = tf.contrib.layers.fully_connected(outputs[:,-1],5,activation_fn=tf.sigmoid)\n",
    "    \n",
    "    predictions = tf.nn.softmax(logits)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=labels_))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with sentiment_graph.as_default():\n",
    "    correct_pred = tf.equal(tf.argmax(predictions,1),tf.argmax(labels_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/20 Iterarion:5 Train loss: 1.521 Accuracy:0.3340\n",
      "Epoch: 0/20 Iterarion:10 Train loss: 1.520 Accuracy:0.2891\n",
      "Epoch: 0/20 Iterarion:15 Train loss: 1.522 Accuracy:0.3164\n",
      "Epoch: 0/20 Iterarion:20 Train loss: 1.508 Accuracy:0.3379\n",
      "Epoch: 0/20 Iterarion:25 Train loss: 1.518 Accuracy:0.2871\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:30 Train loss: 1.505 Accuracy:0.3477\n",
      "Epoch: 0/20 Iterarion:35 Train loss: 1.497 Accuracy:0.3477\n",
      "Epoch: 0/20 Iterarion:40 Train loss: 1.496 Accuracy:0.3203\n",
      "Epoch: 0/20 Iterarion:45 Train loss: 1.512 Accuracy:0.3398\n",
      "Epoch: 0/20 Iterarion:50 Train loss: 1.504 Accuracy:0.3262\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:55 Train loss: 1.521 Accuracy:0.2969\n",
      "Epoch: 0/20 Iterarion:60 Train loss: 1.515 Accuracy:0.3223\n",
      "Epoch: 0/20 Iterarion:65 Train loss: 1.498 Accuracy:0.3457\n",
      "Epoch: 0/20 Iterarion:70 Train loss: 1.536 Accuracy:0.2969\n",
      "Epoch: 0/20 Iterarion:75 Train loss: 1.518 Accuracy:0.3008\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:80 Train loss: 1.515 Accuracy:0.3164\n",
      "Epoch: 0/20 Iterarion:85 Train loss: 1.503 Accuracy:0.3262\n",
      "Epoch: 0/20 Iterarion:90 Train loss: 1.517 Accuracy:0.3359\n",
      "Epoch: 0/20 Iterarion:95 Train loss: 1.525 Accuracy:0.3262\n",
      "Epoch: 0/20 Iterarion:100 Train loss: 1.501 Accuracy:0.2910\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:105 Train loss: 1.539 Accuracy:0.3145\n",
      "Epoch: 0/20 Iterarion:110 Train loss: 1.521 Accuracy:0.3242\n",
      "Epoch: 0/20 Iterarion:115 Train loss: 1.509 Accuracy:0.3125\n",
      "Epoch: 0/20 Iterarion:120 Train loss: 1.551 Accuracy:0.2988\n",
      "Epoch: 0/20 Iterarion:125 Train loss: 1.506 Accuracy:0.3027\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:130 Train loss: 1.507 Accuracy:0.3281\n",
      "Epoch: 0/20 Iterarion:135 Train loss: 1.503 Accuracy:0.3125\n",
      "Epoch: 0/20 Iterarion:140 Train loss: 1.505 Accuracy:0.3066\n",
      "Epoch: 0/20 Iterarion:145 Train loss: 1.518 Accuracy:0.3125\n",
      "Epoch: 0/20 Iterarion:150 Train loss: 1.523 Accuracy:0.3164\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:155 Train loss: 1.489 Accuracy:0.3438\n",
      "Epoch: 0/20 Iterarion:160 Train loss: 1.492 Accuracy:0.3574\n",
      "Epoch: 0/20 Iterarion:165 Train loss: 1.512 Accuracy:0.2930\n",
      "Epoch: 0/20 Iterarion:170 Train loss: 1.523 Accuracy:0.2930\n",
      "Epoch: 0/20 Iterarion:175 Train loss: 1.520 Accuracy:0.3066\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:180 Train loss: 1.516 Accuracy:0.3125\n",
      "Epoch: 0/20 Iterarion:185 Train loss: 1.511 Accuracy:0.3184\n",
      "Epoch: 0/20 Iterarion:190 Train loss: 1.498 Accuracy:0.3184\n",
      "Epoch: 0/20 Iterarion:195 Train loss: 1.521 Accuracy:0.3125\n",
      "Epoch: 0/20 Iterarion:200 Train loss: 1.530 Accuracy:0.2969\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:205 Train loss: 1.530 Accuracy:0.3223\n",
      "Epoch: 0/20 Iterarion:210 Train loss: 1.516 Accuracy:0.2773\n",
      "Epoch: 0/20 Iterarion:215 Train loss: 1.538 Accuracy:0.2871\n",
      "Epoch: 0/20 Iterarion:220 Train loss: 1.517 Accuracy:0.3066\n",
      "Epoch: 0/20 Iterarion:225 Train loss: 1.526 Accuracy:0.2910\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:230 Train loss: 1.525 Accuracy:0.3008\n",
      "Epoch: 0/20 Iterarion:235 Train loss: 1.510 Accuracy:0.3242\n",
      "Epoch: 0/20 Iterarion:240 Train loss: 1.533 Accuracy:0.2988\n",
      "Epoch: 0/20 Iterarion:245 Train loss: 1.548 Accuracy:0.3203\n",
      "Epoch: 0/20 Iterarion:250 Train loss: 1.504 Accuracy:0.3340\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:255 Train loss: 1.555 Accuracy:0.2559\n",
      "Epoch: 0/20 Iterarion:260 Train loss: 1.510 Accuracy:0.2988\n",
      "Epoch: 0/20 Iterarion:265 Train loss: 1.538 Accuracy:0.2988\n",
      "Epoch: 0/20 Iterarion:270 Train loss: 1.526 Accuracy:0.3203\n",
      "Epoch: 0/20 Iterarion:275 Train loss: 1.523 Accuracy:0.3047\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:280 Train loss: 1.498 Accuracy:0.3008\n",
      "Epoch: 0/20 Iterarion:285 Train loss: 1.511 Accuracy:0.2969\n",
      "Epoch: 0/20 Iterarion:290 Train loss: 1.496 Accuracy:0.3340\n",
      "Epoch: 0/20 Iterarion:295 Train loss: 1.521 Accuracy:0.3516\n",
      "Epoch: 0/20 Iterarion:300 Train loss: 1.530 Accuracy:0.3066\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:305 Train loss: 1.506 Accuracy:0.3359\n",
      "Epoch: 0/20 Iterarion:310 Train loss: 1.498 Accuracy:0.3242\n",
      "Epoch: 0/20 Iterarion:315 Train loss: 1.516 Accuracy:0.3242\n",
      "Epoch: 0/20 Iterarion:320 Train loss: 1.519 Accuracy:0.3730\n",
      "Epoch: 0/20 Iterarion:325 Train loss: 1.520 Accuracy:0.3184\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:330 Train loss: 1.485 Accuracy:0.3379\n",
      "Epoch: 0/20 Iterarion:335 Train loss: 1.507 Accuracy:0.3105\n",
      "Epoch: 0/20 Iterarion:340 Train loss: 1.516 Accuracy:0.3066\n",
      "Epoch: 0/20 Iterarion:345 Train loss: 1.498 Accuracy:0.3223\n",
      "Epoch: 0/20 Iterarion:350 Train loss: 1.521 Accuracy:0.3125\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:355 Train loss: 1.513 Accuracy:0.2988\n",
      "Epoch: 0/20 Iterarion:360 Train loss: 1.500 Accuracy:0.2949\n",
      "Epoch: 0/20 Iterarion:365 Train loss: 1.499 Accuracy:0.3438\n",
      "Epoch: 0/20 Iterarion:370 Train loss: 1.529 Accuracy:0.3164\n",
      "Epoch: 0/20 Iterarion:375 Train loss: 1.513 Accuracy:0.3633\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:380 Train loss: 1.544 Accuracy:0.2949\n",
      "Epoch: 0/20 Iterarion:385 Train loss: 1.520 Accuracy:0.3184\n",
      "Epoch: 0/20 Iterarion:390 Train loss: 1.513 Accuracy:0.3301\n",
      "Epoch: 0/20 Iterarion:395 Train loss: 1.505 Accuracy:0.3066\n",
      "Epoch: 0/20 Iterarion:400 Train loss: 1.519 Accuracy:0.3223\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 0/20 Iterarion:405 Train loss: 1.520 Accuracy:0.3125\n",
      "Epoch: 1/20 Iterarion:410 Train loss: 1.493 Accuracy:0.3320\n",
      "Epoch: 1/20 Iterarion:415 Train loss: 1.542 Accuracy:0.2969\n",
      "Epoch: 1/20 Iterarion:420 Train loss: 1.529 Accuracy:0.2852\n",
      "Epoch: 1/20 Iterarion:425 Train loss: 1.543 Accuracy:0.3008\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 1/20 Iterarion:430 Train loss: 1.532 Accuracy:0.2930\n",
      "Epoch: 1/20 Iterarion:435 Train loss: 1.496 Accuracy:0.3516\n",
      "Epoch: 1/20 Iterarion:440 Train loss: 1.509 Accuracy:0.3555\n",
      "Epoch: 1/20 Iterarion:445 Train loss: 1.513 Accuracy:0.3145\n",
      "Epoch: 1/20 Iterarion:450 Train loss: 1.507 Accuracy:0.2969\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 1/20 Iterarion:455 Train loss: 1.524 Accuracy:0.2793\n",
      "Epoch: 1/20 Iterarion:460 Train loss: 1.506 Accuracy:0.3066\n",
      "Epoch: 1/20 Iterarion:465 Train loss: 1.497 Accuracy:0.3574\n",
      "Epoch: 1/20 Iterarion:470 Train loss: 1.514 Accuracy:0.3105\n",
      "Epoch: 1/20 Iterarion:475 Train loss: 1.504 Accuracy:0.3066\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 1/20 Iterarion:480 Train loss: 1.519 Accuracy:0.3125\n",
      "Epoch: 1/20 Iterarion:485 Train loss: 1.536 Accuracy:0.3145\n",
      "Epoch: 1/20 Iterarion:490 Train loss: 1.498 Accuracy:0.3438\n",
      "Epoch: 1/20 Iterarion:495 Train loss: 1.545 Accuracy:0.2930\n",
      "Epoch: 1/20 Iterarion:500 Train loss: 1.493 Accuracy:0.3945\n",
      "Val loss: 0.323 Val acc: 0.3105\n",
      "Epoch: 1/20 Iterarion:505 Train loss: 1.515 Accuracy:0.3320\n",
      "Epoch: 1/20 Iterarion:510 Train loss: 1.531 Accuracy:0.3184\n",
      "Epoch: 1/20 Iterarion:515 Train loss: 1.515 Accuracy:0.3008\n",
      "Epoch: 1/20 Iterarion:520 Train loss: 1.522 Accuracy:0.2988\n",
      "Epoch: 1/20 Iterarion:525 Train loss: 1.512 Accuracy:0.3320\n",
      "Val loss: 0.323 Val acc: 0.3105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-166-eaead8391047>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                    \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                    initial_state:state}\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with sentiment_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "with tf.Session(graph=sentiment_graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state =  sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_sequence_batches(train_x, train_y, batch_size),1):\n",
    "            feed = {inputs_:x,\n",
    "                   labels_:y,\n",
    "                   keep_prob:0.8,\n",
    "                   initial_state:state}\n",
    "            loss, state, _, acc = sess.run([cost,final_state,optimizer,accuracy],feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                     \"Iterarion:{}\".format(iteration),\n",
    "                     \"Train loss: {:.3f}\".format(loss),\n",
    "                     \"Accuracy:{:.4f}\".format(acc))\n",
    "                \n",
    "            if iteration%25==0:\n",
    "                val_loss = []\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x,y in get_sequence_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_:x,\n",
    "                           labels_:y,\n",
    "                           keep_prob:1.0,\n",
    "                           initial_state:val_state}\n",
    "                    batch_loss,val_state,batch_acc = sess.run([cost,final_state,accuracy],feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                    val_loss.append(batch_loss)\n",
    "                    \n",
    "                print(\"Val loss: {:.3f}\".format(np.mean(val_loss)),\n",
    "                     \"Val acc: {:.4f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "test_acc= []\n",
    "with tf.Session(graph=sentiment_graph) as sess:\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size,tf.float32))\n",
    "    for ii, (x, y) in enumerate(get_sequence_batches(test_x, test_y, batch_size),1):\n",
    "        feed = {inputs_:x,\n",
    "               labels_:y,\n",
    "               keep_prob:1,\n",
    "               initial_state:test_state}\n",
    "        \n",
    "        batch_loss,test_state,batch_acc = sess.run([cost,final_state,accuracy],feed_dict=feed)\n",
    "        \n",
    "        test_loss.append(batch_loss)\n",
    "        test_acc.append(batch_acc)\n",
    "        \n",
    "    print(\"Test loss: {:.3f}\".format(np.mean(test_loss)),\n",
    "         \"Test accuracy {:.4f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
